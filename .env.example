# Server Configuration
PORT=3000
NODE_ENV=development

# PostgreSQL Configuration (for Docker)
POSTGRES_USER=dpuser
POSTGRES_PASSWORD=dppassword
POSTGRES_DB=document_processor
POSTGRES_PORT=5436

# Database Configuration (for local development)
# Docker uses: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
DATABASE_URL=postgresql://dpuser:dppassword@localhost:5436/document_processor

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# File Upload Configuration
MAX_FILE_SIZE=50485760
UPLOAD_DIR=./uploads
ALLOWED_FILE_TYPES=.pdf,.docx,.xlsx,.doc,.xls

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
# Remote Ollama instance (e.g., ngrok URL: https://abc123.ngrok.io or external IP: http://192.168.1.100:11434)
OLLAMA_REMOTE_URL=

# OpenAI Configuration
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4-turbo-preview

# Google Gemini Configuration
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# LangChain Configuration
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=

# AI Processing Configuration
DEFAULT_AI_PROVIDER=ollama
MAX_TOKENS_PER_REQUEST=4096
CONVERSATION_TTL_SECONDS=86400
MAX_CONCURRENT_PROCESSING=5

# Czech Language Support
DEFAULT_LANGUAGE=cs
FALLBACK_LANGUAGE=en

# Session Configuration
SESSION_EXPIRE_SECONDS=3600
MAX_ACTIVE_SESSIONS=100

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# WebSocket Configuration
CORS_ORIGIN=*

# Multi-Model Configuration
# Format: provider:model:enabled:baseUrl,provider:model:enabled:baseUrl
# Example: ollama:llama3.1:true:,ollama:mistral:true:,openai:gpt-4:false:
# Leave empty to use DEFAULT_AI_PROVIDER only
MULTI_MODEL_CONFIG=

# MarkItDown Parser Service (optional)
# If using the Python MarkItDown service for enhanced PDF parsing
MARKITDOWN_URL=http://localhost:5000
